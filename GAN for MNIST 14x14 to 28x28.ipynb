{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "  \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, UpSampling2D, Conv2DTranspose, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate, LeakyReLU, BatchNormalization, Dense, Activation, Reshape\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "X_train = np.reshape(X_train, (-1, 28, 28, 1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "def build_generator(image_size):\n",
    "    input1 = Input(shape=(None, None, 1))\n",
    "    \n",
    "    input11 = UpSampling2D()(input1)\n",
    "    \n",
    "    # [C L B C L B]\n",
    "    model1 = Conv2D(16, (3, 3), strides=(1, 1), padding='same')(input11)\n",
    "    model1 = LeakyReLU(alpha=0.2)(model1)\n",
    "    model1 = BatchNormalization(momentum=0.8)(model1)\n",
    "    model1 = Conv2D(16, (3, 3), strides=(1, 1), padding='same')(model1)\n",
    "    model1 = LeakyReLU(alpha=0.2)(model1)\n",
    "    model1 = BatchNormalization(momentum=0.8)(model1)\n",
    "    \n",
    "    # [C L B C L B C L B]\n",
    "    model2 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(model1)\n",
    "    model2 = LeakyReLU(alpha=0.2)(model2)\n",
    "    model2 = BatchNormalization(momentum=0.8)(model2)\n",
    "    model2 = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(model2)\n",
    "    model2 = LeakyReLU(alpha=0.2)(model2)\n",
    "    model2 = BatchNormalization(momentum=0.8)(model2)\n",
    "    model2 = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(model2)\n",
    "    model2 = LeakyReLU(alpha=0.2)(model2)\n",
    "    model2 = BatchNormalization(momentum=0.8)(model2)\n",
    "\n",
    "    # [C L B C L B C L B]\n",
    "    model3 = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(model2)\n",
    "    model3 = LeakyReLU(alpha=0.2)(model3)\n",
    "    model3 = BatchNormalization(momentum=0.8)(model3)\n",
    "    model3 = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(model3)\n",
    "    model3 = LeakyReLU(alpha=0.2)(model3)\n",
    "    model3 = BatchNormalization(momentum=0.8)(model3)\n",
    "    model3 = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(model3)\n",
    "    model3 = LeakyReLU(alpha=0.2)(model3)\n",
    "    model3 = BatchNormalization(momentum=0.8)(model3)\n",
    "\n",
    "    # [Conc L B C L B C L B]\n",
    "    model4 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(model3), model2], axis=3)\n",
    "    model4 = LeakyReLU(alpha=0.2)(model4)\n",
    "    model4 = BatchNormalization(momentum=0.8)(model4)\n",
    "    model4 = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(model4)\n",
    "    model4 = LeakyReLU(alpha=0.2)(model4)\n",
    "    model4 = BatchNormalization(momentum=0.8)(model4)\n",
    "    model4 = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(model4)\n",
    "    model4 = LeakyReLU(alpha=0.2)(model4)\n",
    "    model4 = BatchNormalization(momentum=0.8)(model4)\n",
    "    \n",
    "    # [Conc L B C L B C L B]\n",
    "    model5 = concatenate([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(model4), model1], axis=3)\n",
    "    model5 = LeakyReLU(alpha=0.2)(model5)\n",
    "    model5 = BatchNormalization(momentum=0.8)(model5)\n",
    "    model5 = Conv2D(16, (3, 3), strides=(1, 1), padding='same')(model5)\n",
    "    model5 = LeakyReLU(alpha=0.2)(model5)\n",
    "    model5 = BatchNormalization(momentum=0.8)(model5)\n",
    "    model5 = Conv2D(16, (3, 3), strides=(1, 1), padding='same')(model5)\n",
    "    model5 = LeakyReLU(alpha=0.2)(model5)\n",
    "    model5 = BatchNormalization(momentum=0.8)(model5)\n",
    "    \n",
    "    # [Conc L B C_sigmoid]\n",
    "    model6 = concatenate([Conv2D(16, (1, 1), padding='same')(model5), input11], axis=3)\n",
    "    model6 = LeakyReLU(alpha=0.2)(model6)\n",
    "    model6 = BatchNormalization(momentum=0.8)(model6)\n",
    "    model6 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(model6)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_size):\n",
    "    # \n",
    "    input1 = Input(shape=(None, None, 1))\n",
    "    input2 = Input(shape=(None, None, 1))\n",
    "    \n",
    "    model1 = UpSampling2D()(input1)\n",
    "    model1 = Conv2D(16, (3, 3), strides=(1,1), padding='same')(model1)\n",
    "    model1 = LeakyReLU(alpha=0.2)(model1)\n",
    "    model1 = BatchNormalization(momentum=0.8)(model1)\n",
    "    model1 = Conv2D(16, (3, 3), strides=(1,1), padding='same')(model1)\n",
    "    model1 = LeakyReLU(alpha=0.2)(model1)\n",
    "    model1 = BatchNormalization(momentum=0.8)(model1)\n",
    "    \n",
    "    model = Conv2D(16, (3, 3), strides=(1,1), padding='same')(input2)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Conv2D(16, (3, 3), strides=(1,1), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = concatenate([model, model1], axis=3)\n",
    "    \n",
    "    model = Conv2D(32, (3, 3), strides=(2,2), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Conv2D(64, (3, 3), strides=(1,1), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Conv2D(64, (3, 3), strides=(1,1), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), strides=(2,2), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Conv2D(256, (3, 3), strides=(1,1), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Conv2D(256, (3, 3), strides=(1,1), padding='same')(model)\n",
    "    model = GlobalAveragePooling2D()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Dense(1024)(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = BatchNormalization(momentum=0.8)(model)\n",
    "    model = Dense(512)(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    model = Dense(1)(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "\n",
    "    return Model(inputs=[input1, input2], outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, None, None, 1 165318      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            1824769     input_4[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,990,087\n",
      "Trainable params: 164,260\n",
      "Non-trainable params: 1,825,827\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.001, 0.5)\n",
    "generator = build_generator(image_size)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "optimizer1 = Adam(0.0002, 0.5)\n",
    "discriminator = build_discriminator(image_size)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The generator takes noise as input and generated imgs\n",
    "z = Input(shape=(None, None, 1))\n",
    "img = generator(z)\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator([z, img])\n",
    "\n",
    "# The combined model  (stacked generator and discriminator) takes\n",
    "# noise as input => generates images => determines validity \n",
    "combined = Model(z, [valid, img])\n",
    "combined.compile(loss=['binary_crossentropy', 'mean_absolute_error'], optimizer=optimizer, metrics = ['accuracy'])\n",
    "\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/tf-1.12/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.695150, acc.: 0.00%] [G loss: 1.340537]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 2\n",
    "half_batch = int(batch_size/2)\n",
    "def reduce_resolution(ims):\n",
    "    O, M, N, P = ims.shape\n",
    "    K = 2\n",
    "    L = 2\n",
    "\n",
    "    MK = M // K\n",
    "    NL = N // L\n",
    "    return ims.reshape(-1, MK, K, NL, L).mean(axis=(2, 4)).reshape(O, MK, NL, P)\n",
    "\n",
    "def upsize(ims):\n",
    "    return ims.repeat(2, axis = 1).repeat(2, axis = 2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Select a random half batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "    noise = reduce_resolution(imgs)\n",
    "\n",
    "    idx1 = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs1 = X_train[idx1]\n",
    "    noise1 = reduce_resolution(imgs1)\n",
    "\n",
    "    # Generate a half batch of new images\n",
    "    gen_imgs = generator.predict(noise1)\n",
    "    # Train the discriminator\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch([noise, imgs], np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch([noise1, gen_imgs], np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "\n",
    "    idx2 = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    noise2 = reduce_resolution(X_train[idx2])\n",
    "\n",
    "    # The generator wants the discriminator to label the generated samples\n",
    "    # as valid (ones)\n",
    "    valid_y = np.array([1] * batch_size)\n",
    "    \n",
    "    # Train the generator\n",
    "    g_loss = combined.train_on_batch(noise2, [valid_y, X_train[idx2]])\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0]))\n",
    "        fig, ax = plt.subplots(1, 3)\n",
    "        ax[0].imshow(np.reshape(noise1[0], (14, 14)))\n",
    "        ax[1].imshow(np.reshape(gen_imgs[0], (28, 28)))\n",
    "        ax[2].imshow(np.reshape(imgs1[0], (28, 28)))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generator.save('./models/generator_mnist.h5')\n",
    "discriminator.save('./models/discriminator_mnist.h5')\n",
    "combined.save('./models/combined_mnist.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
